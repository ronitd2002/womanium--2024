# Task 3

### Def :
### Quanvolutional Filters

Quanvolutional filters are designed to produce feature maps by applying quantum transformations to spatially-local subsections of an input tensor. Unlike classical convolutional filters that rely on simple element-wise matrix multiplication, quanvolutional filters utilize quantum circuits to transform the input data. These quantum circuits can be either structured or randomly generated, providing a unique approach to feature extraction in quantum neural networks.

### Application:

### Quanvolution in our project

This section extends the concept of convolution to quantum variational circuits. The following procedure, inspired by the approach detailed in [Ref](https://arxiv.org/abs/1904.04767), outlines how quantum convolution can be implemented. The associated scheme is illustrated in the figure at the top of this tutorial.

1. **Embedding Input Regions:** A small region of the input image, such as a $2\times2$ square, is encoded into a quantum circuit. In this example, this is done using parametrized rotations applied to qubits initialized in the ground state.

2. **Quantum Computation:** A quantum computation is performed on the system using a unitary `U`. This unitary can be generated by a variational quantum circuit or by a random circuit, as suggested in [Ref](https://arxiv.org/abs/1904.04767).

3. **Measurement:** The quantum system is measured, producing a list of classical expectation values. While the measurement results can be post-processed as proposed in [Ref](https://arxiv.org/abs/1904.04767), this demo directly utilizes the raw expectation values for simplicity.

4. **Mapping to Output Channels:** Similar to a classical convolution layer, each expectation value is mapped to a different channel of a single output pixel.

5. **Scanning the Input Image:** By iterating this procedure across different regions, the entire input image can be scanned, resulting in an output structured as a multi-channel image.

6. **Subsequent Layers:** The quantum convolution layer can be followed by additional quantum or classical layers.

The key distinction between quantum and classical convolution is that a quantum circuit can produce highly complex kernels that may be classically intractable to compute.

### What exactly did we do?

We applied this quanvolutional neural network (QNN) to the MNIST handwritten digit detection dataset. The MNIST dataset consists of 28x28 grayscale images, each representing a handwritten digit from 0 to 9.

#### Features of the Quanvolutional Neural Network:

- **Quantum Feature Extraction:** Small patches of the input image (e.g., $2\times2$ regions) were encoded into quantum circuits using parametrized rotations. This allowed the network to extract quantum-enhanced features from the input data.

- **Hybrid Architecture:** The QNN combines quantum and classical layers. After quantum convolution, the output was processed by classical layers, enabling the model to leverage both quantum and classical computational strengths.

- **Quantum Pooling:** To reduce the dimensionality of the output while retaining essential features, quantum pooling was applied after the quanvolutional layers, analogous to classical pooling operations.

- **Training and Optimization:** The network was trained using a hybrid quantum-classical optimization strategy, where the quantum parameters were optimized alongside the classical ones using gradient-based methods.

- **Enhanced Kernel Complexity:** The quantum circuits generated complex kernels that are challenging to compute classically, potentially improving the model's ability to distinguish subtle variations in the input images.

The results for the same are demonstrated in the notebook in the directory.